#CONTEXT
Submission Guidelines:

You must complete and submit all responses directly in the Microsoft Forms link provided.
You may upload your deliverables as Canva document/presentation links where applicable. (Please do not share personal Google Drive or OneDrive links).
For coding tasks: Paste your code snippets (e.g., Python or SQL) directly into the answer fields, a GitHub repo link or Jupyter notebook link.
Make sure all shared links are viewable without log in or access request.
Time Estimate: The full test should take approximately 4-6 hours. You may take breaks, but please submit your work within 72 hours of receiving the test. We would like to see the high level concept, your ideas on how to implement the tool.

1. Overview:
In this assessment, you are required to build a tool that uses Large Language Models (LLMs) to extract structured information from unstructured resumes (CVs). The goal is to evaluate your ability to work with LLMs, handle PDF files, and design a reproducible evaluation method for your tool.
You may use any LLM provider (open or closed source), and any orchestration frameworks or tools such as LangChain, LangGraph, CrewAI, OpenAI SDK, etc.
This is a design-and-build exercise. We are interested in your end-to-end thinking: how you process inputs, prompt or design the LLM interaction, validate outputs, and document the solution.

2. Dataset:
Use the following resume dataset:
https://www.kaggle.com/datasets/snehaanbhawal/resume-dataset?select=data
Important: Only use files from the "INFORMATION TECHNOLOGY" folder. Submissions using files outside this folder will not be accepted.

3.Evaluation Criteria:
Multiple format handling: How well you use the LLM to extract the entity from the unstructured data (plain-text or scanned PDF files)
Entity Extraction: How accurately you use the LLM to implement the prompt to extract entities and store them in the JSON file
Result validation: Which technique you’re going to use to evaluate the result generated by LLM

4. #Your Task:
You will build a tool that can extract specific structured data fields from CVs in PDF format. The tool must extract the following information:
Name – full name of the candidate
Email – valid email address
Phone – phone number
Skills – a list of technical and professional skills
Education – including degree, institution name, and graduation year
Experience – for each job: job title, company name, years worked, and a short description
Certifications – list of certifications, if available
Languages – languages the candidate can speak or write
You should extract these values and structure the output as a JSON object for each resume.
Design prompts or an LLM interaction method to extract the information above from the PDF files.

------------------------------------------------------------------------------------------------------------------------------------------------------

Documentation (short report or slide): Show your approach to implement this tool (technology stack, workflow, etc.), how you observe the result generated by LLM, limitations of this tool and the improvements in the future.

1. Text-based PDFs (digitally generated) + Scanned PDFs (images requiring OCR) Note You may use any OCR tool of your choice, such as Tesseract.
    - Multiple format handling: CONVERT FROM UNSTRUCTURE DATA INTO STRUCTURE DATA SECTION 2-3

2. Define and implement a systematic evaluation method for your tool
    - Entity Extraction: BUILD LLM PROMTP ASSOCIATED WITH METADATA AND RESPONSE TO EXTRACT 
    - Result validation: EXTRACT GROUND TRUTH FROM CSV FILE HTML (REGEX) -> EVALUATE LLM PERFORMANCE WITH IT USING ACCURACY PER TERMS + Advanced SELF EVALUATION LLM

Workflow PNG files attachments

Limitation: 
+ Time to explore componments of html in ground truth 
+ Token to call open api to test different promp templates